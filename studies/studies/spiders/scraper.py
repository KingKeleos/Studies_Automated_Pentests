from pathlib import Path
from bs4 import BeautifulSoup
from enum import Enum
import scrapy
import os
import sys

class Spider(scrapy.Spider):
    name = 'mainSpider'
    urls = os.environ['TARGET']

    def start_requests(self):
        scrapy.Request(url=self.urls, callback=self.parse)
        return super().start_requests()
    
    def parse(self, response):
        links = response.css('a::attr(href)').extract()
        for url in links:
            yield scrapy.http.Request(url, callback=self.parse_page)
        title = response.css('title::text').getall()
        filename = f'scraped-{title}.html'
        Path(filename).write_bytes(response.body)
        print(title)


def get_token(source):
    soup = BeautifulSoup(source, "html.parser")
    return soup.find('input', { "type" : "hidden" })['value']


def find_form(source):
    soup = BeautifulSoup(source, "html.parser")
    return soup.find('forms')['value']

