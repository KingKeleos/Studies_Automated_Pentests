from pathlib import Path
from bs4 import BeautifulSoup
from enum import Enum
from documentation import logger
import scrapy

class Spider(scrapy.Spider):
    name = 'mainSpider'
    url = ""

    def start_requests(self):
        logger.log("Beginning to Scrape Website", "Scraping")
        scrapy.Request(url=self.url, callback=self.parse)
        return super().start_requests()
    
    def parse(self, response):
        links = response.css('a::attr(href)').extract()
        for url in links:
            yield scrapy.http.Request(url, callback=self.parse_page)
        page = response.url.split("/")[2]
        title = response.xpath('//h1/text()').get
        logger.log("Parsing the Website %s" % title, "Parsing")
        filename = f'scraped-{page}.html'
        Path(filename).write_bytes(response.body)
        self.log(f'Saved file {filename}')

    def __init__(self, url):
        self.url = url


def get_token(source):
    soup = BeautifulSoup(source, "html.parser")
    return soup.find('input', { "type" : "hidden" })['value']


def find_form(source):
    soup = BeautifulSoup(source, "html.parser")
    return soup.find('forms')['value']

